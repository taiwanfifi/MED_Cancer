#!/usr/bin/env python3
"""
Experiment 0: Cancer Data Exploration & Feasibility
====================================================
Quick exploration to validate data availability and identify
the most promising research directions.

This runs FAST â€” download small datasets, compute basic stats,
and output a feasibility report.
"""

import os
import json
import logging
from pathlib import Path
from datetime import datetime

import numpy as np
import pandas as pd
import requests
from tqdm import tqdm

BASE_DIR = Path("/workspace/cancer_research")
DATA_DIR = BASE_DIR / "data"
RESULTS_DIR = BASE_DIR / "results" / "exploration"

for d in [DATA_DIR, RESULTS_DIR, DATA_DIR / "tcga", DATA_DIR / "depmap",
          DATA_DIR / "drug_repurpose"]:
    d.mkdir(parents=True, exist_ok=True)

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)


def explore_tcga_gdc():
    """Check TCGA data availability via GDC API."""
    logger.info("=== Exploring TCGA/GDC ===")

    # Get project summary
    url = "https://api.gdc.cancer.gov/projects"
    params = {
        "filters": json.dumps({
            "op": "in",
            "content": {"field": "program.name", "value": ["TCGA"]}
        }),
        "fields": "project_id,name,primary_site,summary.case_count,summary.file_count,summary.data_categories.data_category,summary.data_categories.file_count",
        "size": 100,
        "format": "JSON"
    }

    response = requests.get(url, params=params, timeout=30)
    data = response.json()

    projects = []
    for hit in data["data"]["hits"]:
        project = {
            "project_id": hit.get("project_id", ""),
            "name": hit.get("name", ""),
            "primary_site": hit.get("primary_site", [""])[0] if isinstance(hit.get("primary_site"), list) else hit.get("primary_site", ""),
            "case_count": hit.get("summary", {}).get("case_count", 0),
            "file_count": hit.get("summary", {}).get("file_count", 0),
        }

        # Data categories
        for cat in hit.get("summary", {}).get("data_categories", []):
            project[f"files_{cat['data_category'].replace(' ', '_')}"] = cat['file_count']

        projects.append(project)

    df = pd.DataFrame(projects).sort_values("case_count", ascending=False)
    df.to_csv(RESULTS_DIR / "tcga_projects_summary.csv", index=False)
    logger.info(f"TCGA: {len(df)} projects, total {df['case_count'].sum()} cases")
    logger.info(f"Top 10 by sample size:\n{df[['project_id', 'name', 'case_count']].head(10).to_string()}")

    return df


def explore_depmap():
    """Check DepMap data availability."""
    logger.info("=== Exploring DepMap ===")

    # DepMap downloads
    depmap_files = {
        "gene_effect": "https://ndownloader.figshare.com/files/34990036",  # CRISPR gene effect
        "cell_lines": "https://ndownloader.figshare.com/files/35020903",  # Cell line info
        "expression": "https://ndownloader.figshare.com/files/34989919",  # Expression
    }

    # Try to get cell line info (small file)
    try:
        logger.info("Downloading DepMap cell line info...")
        # Use the DepMap portal API
        url = "https://depmap.org/portal/api/cell_lines"
        # Alternative: download from figshare
        # For now, just check what's available
        logger.info("DepMap data available via portal and figshare")
    except Exception as e:
        logger.warning(f"DepMap access error: {e}")

    return depmap_files


def explore_dgidb():
    """Download and explore DGIdb interactions."""
    logger.info("=== Exploring DGIdb ===")

    output_file = DATA_DIR / "drug_repurpose" / "dgidb_interactions.tsv"
    if not output_file.exists():
        # Try multiple URLs
        urls = [
            "https://dgidb.org/data/monthly_tsvs/2024-Feb/interactions.tsv",
            "https://dgidb.org/data/monthly_tsvs/2023-Oct/interactions.tsv",
        ]

        for url in urls:
            try:
                logger.info(f"Trying DGIdb: {url}")
                df = pd.read_csv(url, sep='\t', low_memory=False, timeout=60)
                df.to_csv(output_file, sep='\t', index=False)
                logger.info(f"DGIdb downloaded: {df.shape}")
                break
            except Exception as e:
                logger.warning(f"Failed: {e}")
                df = None
    else:
        df = pd.read_csv(output_file, sep='\t', low_memory=False)

    if df is not None:
        logger.info(f"DGIdb: {len(df)} interactions")
        logger.info(f"  Unique drugs: {df['drug_name'].nunique() if 'drug_name' in df.columns else 'N/A'}")
        logger.info(f"  Unique genes: {df['gene_name'].nunique() if 'gene_name' in df.columns else 'N/A'}")
        logger.info(f"  Interaction types: {df['interaction_group_score'].describe() if 'interaction_group_score' in df.columns else 'N/A'}")

    return df


def explore_drugcomb():
    """Check DrugComb synergy data."""
    logger.info("=== Exploring DrugComb ===")

    # DrugComb API
    try:
        url = "https://drugcomb.fimm.fi/api/summary"
        response = requests.get(url, timeout=30)
        if response.status_code == 200:
            data = response.json()
            logger.info(f"DrugComb summary: {json.dumps(data, indent=2)[:500]}")
        else:
            logger.info(f"DrugComb API returned {response.status_code}")
    except Exception as e:
        logger.warning(f"DrugComb API error: {e}")


def download_tcga_clinical_all():
    """Download clinical data for all major cancer types."""
    logger.info("=== Downloading TCGA Clinical Data ===")

    cancer_types = ["BRCA", "LUAD", "UCEC", "KIRC", "HNSC",
                    "LGG", "THCA", "LUSC", "PRAD", "STAD",
                    "BLCA", "LIHC", "COAD", "OV", "CESC"]

    all_clinical = []

    for ct in tqdm(cancer_types, desc="Downloading clinical"):
        output_file = DATA_DIR / "tcga" / f"{ct}_clinical.json"
        if output_file.exists():
            with open(output_file) as f:
                records = json.load(f)
            all_clinical.extend(records)
            continue

        try:
            filters = {
                "op": "in",
                "content": {"field": "project.project_id", "value": [f"TCGA-{ct}"]}
            }

            fields = [
                "submitter_id",
                "demographic.vital_status",
                "demographic.days_to_death",
                "demographic.gender",
                "demographic.age_at_index",
                "diagnoses.tumor_stage",
                "diagnoses.primary_diagnosis",
                "diagnoses.days_to_last_follow_up",
                "diagnoses.ajcc_pathologic_stage",
                "diagnoses.age_at_diagnosis",
            ]

            params = {
                "filters": json.dumps(filters),
                "fields": ",".join(fields),
                "format": "JSON",
                "size": "2000"
            }

            response = requests.get("https://api.gdc.cancer.gov/cases",
                                   params=params, timeout=60)
            data = response.json()

            records = []
            for hit in data["data"]["hits"]:
                record = {
                    "case_id": hit.get("submitter_id", ""),
                    "cancer_type": ct,
                }

                demo = hit.get("demographic", {})
                record["vital_status"] = demo.get("vital_status", "")
                record["days_to_death"] = demo.get("days_to_death", None)
                record["gender"] = demo.get("gender", "")
                record["age"] = demo.get("age_at_index", None)

                diags = hit.get("diagnoses", [{}])
                if diags:
                    diag = diags[0]
                    record["stage"] = diag.get("ajcc_pathologic_stage", "")
                    record["days_to_follow_up"] = diag.get("days_to_last_follow_up", None)
                    record["diagnosis"] = diag.get("primary_diagnosis", "")

                records.append(record)
                all_clinical.append(record)

            with open(output_file, 'w') as f:
                json.dump(records, f, indent=2)

            logger.info(f"  {ct}: {len(records)} cases")

        except Exception as e:
            logger.warning(f"  {ct}: Error - {e}")

    # Combine all
    if all_clinical:
        df_all = pd.DataFrame(all_clinical)
        df_all.to_parquet(DATA_DIR / "tcga" / "pan_cancer_clinical.parquet")
        logger.info(f"\nTotal clinical data: {len(df_all)} cases across {df_all['cancer_type'].nunique()} types")

        # Basic survival statistics
        df_all['event'] = (df_all['vital_status'] == 'Dead').astype(int)
        df_all['time'] = df_all.apply(
            lambda r: r['days_to_death'] if pd.notna(r['days_to_death'])
            else r.get('days_to_follow_up', 0), axis=1
        )

        survival_summary = df_all.groupby('cancer_type').agg(
            n_cases=('case_id', 'count'),
            mortality_rate=('event', 'mean'),
            median_survival_days=('time', 'median'),
            mean_age=('age', 'mean'),
        ).round(2)

        survival_summary.to_csv(RESULTS_DIR / "pan_cancer_survival_summary.csv")
        logger.info(f"\nSurvival summary:\n{survival_summary.to_string()}")

        return df_all

    return None


def generate_feasibility_report(tcga_df, dgidb_df):
    """Generate a feasibility report for all 10 papers."""
    report = {
        "timestamp": datetime.now().isoformat(),
        "server": "vast.ai RTX 5880 Ada (48GB VRAM)",
        "data_available": {},
        "paper_feasibility": {},
    }

    # TCGA
    if tcga_df is not None:
        report["data_available"]["tcga"] = {
            "projects": len(tcga_df),
            "total_cases": int(tcga_df["case_count"].sum()),
            "data_types": ["gene_expression", "mutations", "clinical",
                          "copy_number", "methylation", "miRNA"],
        }

    # DGIdb
    if dgidb_df is not None:
        report["data_available"]["dgidb"] = {
            "interactions": len(dgidb_df),
            "drugs": int(dgidb_df["drug_name"].nunique()) if "drug_name" in dgidb_df.columns else 0,
            "genes": int(dgidb_df["gene_name"].nunique()) if "gene_name" in dgidb_df.columns else 0,
        }

    # Paper feasibility assessment
    papers = {
        "P1_drug_repurposing": {"feasibility": "HIGH", "data_ready": True, "blocking": None},
        "P2_drug_combo_synergy": {"feasibility": "HIGH", "data_ready": False, "blocking": "Need DrugComb download"},
        "P3_irAE_prediction": {"feasibility": "MEDIUM", "data_ready": False, "blocking": "Need immunotherapy cohort data"},
        "P4_synthetic_lethality": {"feasibility": "HIGH", "data_ready": False, "blocking": "Need DepMap download"},
        "P5_multi_omics_subtyping": {"feasibility": "HIGH", "data_ready": True, "blocking": None},
        "P6_gene_reg_networks": {"feasibility": "HIGH", "data_ready": True, "blocking": None},
        "P7_cancer_llm": {"feasibility": "HIGH", "data_ready": False, "blocking": "Need guidelines corpus"},
        "P8_pathology_model": {"feasibility": "MEDIUM", "data_ready": False, "blocking": "Need histopath images (large)"},
        "P9_liquid_biopsy": {"feasibility": "LOW", "data_ready": False, "blocking": "Need cfDNA datasets"},
        "P10_tme_immunotherapy": {"feasibility": "HIGH", "data_ready": True, "blocking": None},
    }
    report["paper_feasibility"] = papers

    with open(RESULTS_DIR / "feasibility_report.json", 'w') as f:
        json.dump(report, f, indent=2)

    logger.info(f"\nFeasibility Report saved to {RESULTS_DIR / 'feasibility_report.json'}")
    return report


def main():
    logger.info("=" * 60)
    logger.info("EXPERIMENT 0: Data Exploration & Feasibility")
    logger.info(f"Time: {datetime.now()}")
    logger.info("=" * 60)

    # 1. Explore TCGA
    tcga_df = explore_tcga_gdc()

    # 2. Explore DGIdb
    dgidb_df = explore_dgidb()

    # 3. Check DrugComb
    explore_drugcomb()

    # 4. Check DepMap
    explore_depmap()

    # 5. Download all TCGA clinical data
    clinical_df = download_tcga_clinical_all()

    # 6. Generate feasibility report
    report = generate_feasibility_report(tcga_df, dgidb_df)

    logger.info("\n" + "=" * 60)
    logger.info("EXPLORATION COMPLETE")
    logger.info("=" * 60)


if __name__ == "__main__":
    main()
